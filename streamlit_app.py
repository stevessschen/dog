import streamlit as st
from PIL import Image
import cv2
import numpy as np
from ultralytics import YOLO

st.set_page_config(page_title="DogTalk AI MVP", layout="centered")
st.title("ğŸ¶ DogTalk AI MVP")

# ä¸Šå‚³æˆ–ä½¿ç”¨æ”åƒé ­
st.sidebar.header("æ“ä½œæ–¹å¼")
use_webcam = st.sidebar.checkbox("ä½¿ç”¨æ”åƒé ­", value=False)

if use_webcam:
    st.warning("ç›®å‰ Streamlit Cloud ä¸æ”¯æ´ç›´æ¥ webcamï¼Œéœ€è¦æœ¬åœ°æ¸¬è©¦")
else:
    uploaded_file = st.file_uploader("ä¸Šå‚³ç‹—ç‹—åœ–ç‰‡", type=["jpg", "png"])

# è¼‰å…¥ YOLOv8 æ¨¡å‹
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

model = load_model()

def analyze_image(image: Image.Image):
    img_np = np.array(image)
    results = model.predict(img_np, classes=[16])  # COCO 16 = dog
    if len(results[0].boxes) == 0:
        return None, None

    # æ¨™è¨˜æ¡†ç·š
    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)

    # å‡è¨­å§¿æ…‹ / æƒ…ç·’
    pose = "sit"  # ç°¡åŒ–ç¤ºç¯„
    emotion_map = {"sit": "æ”¾é¬†", "stand": "è­¦æˆ’", "lay": "ä¼‘æ¯"}
    emotion = emotion_map.get(pose, "æœªçŸ¥")

    # GPT å»ºè­°
    suggestions = {
        "æ”¾é¬†": "ç‰ ç¾åœ¨å¾ˆæ”¾é¬†ï¼Œå¯ä»¥è¼•é¬†äº’å‹•",
        "è­¦æˆ’": "ç‰ æœ‰é»è­¦æˆ’ï¼Œå»ºè­°ä¿æŒè·é›¢",
        "ä¼‘æ¯": "ç‰ åœ¨ä¼‘æ¯ï¼Œè«‹ä¸è¦æ‰“æ“¾"
    }
    suggestion = suggestions.get(emotion, "è§€å¯Ÿç‰ çš„å‹•ä½œ")

    return cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB), (emotion, suggestion)

# ä¸»æµç¨‹
if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="åŸå§‹åœ–ç‰‡", use_column_width=True)
    result_img, info = analyze_image(image)
    if result_img is None:
        st.warning("æ‰¾ä¸åˆ°ç‹—ç‹—ï¼Œè«‹æ›å¼µåœ–ç‰‡æˆ–èª¿æ•´è§’åº¦")
    else:
        st.image(result_img, caption="åµæ¸¬çµæœ", use_column_width=True)
        st.success(f"æƒ…ç·’: {info[0]}")
        st.info(f"å»ºè­°: {info[1]}")
