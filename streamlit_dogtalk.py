import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
from gtts import gTTS
import tempfile
import platform

st.set_page_config(page_title="DogTalk AI MVP", layout="wide")
st.title("ğŸ¶ DogTalk AI MVP")

# åˆ¤æ–·æ˜¯å¦åœ¨ Cloud
IS_CLOUD = platform.system() == "Linux"

# è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")

model = load_model()

# èªéŸ³è¼¸å‡ºï¼ˆCloud ç”¨æ’­æ”¾å™¨ï¼‰
def speak(text):
    tts = gTTS(text=text, lang="zh-tw")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        st.audio(fp.name)

# åˆ†æåœ–ç‰‡
def analyze(img):
    results = model.predict(img, classes=[16], verbose=False)

    if len(results[0].boxes) == 0:
        return img, "æ‰¾ä¸åˆ°ç‹—ç‹—", "è«‹é‡æ–°æ‹æ”"

    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)

    emotion = "æ”¾é¬†"
    suggestion = "ç‰ ç¾åœ¨å¾ˆæ”¾é¬†ï¼Œå¯ä»¥è¼•é¬†äº’å‹•"

    cv2.putText(img, f"æƒ…ç·’: {emotion}", (10,40),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)
    cv2.putText(img, f"å»ºè­°: {suggestion}", (10,80),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,255), 2)

    return img, emotion, suggestion


# UI
st.subheader("ğŸ“· ä¸Šå‚³ç‹—ç‹—ç…§ç‰‡")
uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="åŸå§‹åœ–ç‰‡", use_column_width=True)

    img_np = np.array(image)
    result_img, emotion, suggestion = analyze(img_np)

    st.image(result_img, caption="AI åˆ†æçµæœ", use_column_width=True)
    st.success(f"æƒ…ç·’åˆ¤æ–·ï¼š{emotion}")
    st.info(f"è¡Œç‚ºå»ºè­°ï¼š{suggestion}")

    speak(suggestion)
