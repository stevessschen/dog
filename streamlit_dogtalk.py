import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
from gtts import gTTS
import tempfile
import platform

st.set_page_config(page_title="DogTalk AI MVP", layout="wide")
st.title("ğŸ¶ DogTalk AI MVP (Cloud + æœ¬åœ° webcam)")

# åˆ¤æ–·æ˜¯å¦ Cloud ç’°å¢ƒ
IS_CLOUD = platform.system() == "Linux" and "KERNEL" in platform.uname().version

# è¼‰å…¥ YOLO æ¨¡å‹
@st.cache_resource
def load_model():
    return YOLO("yolov8n.pt")
model = load_model()

# èªéŸ³æ’­æ”¾ (Cloud ç”¨ st.audio)
def speak(text):
    tts = gTTS(text=text, lang="zh-tw")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        if IS_CLOUD:
            st.audio(fp.name)
        else:
            # æœ¬åœ°æ¸¬è©¦å¯ç”¨ pyttsx3 æˆ– gTTS æ’­æ”¾
            import os
            os.system(f"mpg123 {fp.name} >/dev/null 2>&1")  # Linux æœ¬åœ°æ’­æ”¾
            

# ç‹—ç‹—åµæ¸¬ + æ¡†ç·š + æƒ…ç·’ + å»ºè­°
def analyze_image(image_np):
    results = model.predict(image_np, classes=[16], verbose=False)
    for box in results[0].boxes.xyxy:
        x1, y1, x2, y2 = map(int, box)
        cv2.rectangle(image_np, (x1, y1), (x2, y2), (0, 255, 0), 2)

    pose = "sit"  # ç°¡åŒ–
    emotion_map = {"sit": "æ”¾é¬†", "stand": "è­¦æˆ’", "lay": "ä¼‘æ¯"}
    emotion = emotion_map.get(pose, "æœªçŸ¥")

    suggestions = {
        "æ”¾é¬†": "ç‰ ç¾åœ¨å¾ˆæ”¾é¬†ï¼Œå¯ä»¥è¼•é¬†äº’å‹•",
        "è­¦æˆ’": "ç‰ æœ‰é»è­¦æˆ’ï¼Œå»ºè­°ä¿æŒè·é›¢",
        "ä¼‘æ¯": "ç‰ åœ¨ä¼‘æ¯ï¼Œè«‹ä¸è¦æ‰“æ“¾"
    }
    suggestion = suggestions.get(emotion, "è§€å¯Ÿç‰ çš„å‹•ä½œ")

    cv2.putText(image_np, f"æƒ…ç·’: {emotion}", (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)
    cv2.putText(image_np, f"å»ºè­°: {suggestion}", (10,70),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)

    return image_np, emotion, suggestion

# æ“ä½œé¸æ“‡
mode = st.radio("æ“ä½œæ¨¡å¼", ["ä¸Šå‚³åœ–ç‰‡", "æœ¬åœ° webcam"])

if mode == "ä¸Šå‚³åœ–ç‰‡":
    uploaded_file = st.file_uploader("ä¸Šå‚³ç‹—ç‹—åœ–ç‰‡", type=["jpg","png"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="åŸå§‹åœ–ç‰‡", use_column_width=True)
        img_np = np.array(image)
        result_img, emotion, suggestion = analyze_image(img_np)
        st.image(result_img, caption="åµæ¸¬çµæœ", use_column_width=True)
        st.success(f"æƒ…ç·’: {emotion}")
        st.info(f"å»ºè­°: {suggestion}")
        speak(suggestion)

else:
    if IS_CLOUD:
        st.warning("Cloud ç„¡æ³•ç›´æ¥ä½¿ç”¨ webcamï¼Œæœ¬åœ°æ¸¬è©¦å¯ç”¨")
    else:
        cap = cv2.VideoCapture(0)
        placeholder = st.empty()
        run = st.checkbox("å•Ÿå‹•å³æ™‚ webcam åˆ†æ", value=True)

        while run:
            ret, frame = cap.read()
            if not ret:
                st.warning("ç„¡æ³•è®€å– webcam")
                break
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result_img, emotion, suggestion = analyze_image(frame_rgb)
            placeholder.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))
            speak(suggestion)

        cap.release()
